#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TO DO:
    * address pandas warning
    * finish conda distro


"""

# beginning information
__author__ = 'Kaleb Abram (abram.kaleb@gmail.com)'
__version__ = '0.9'
__date__ = 'December 20, 2022'

# libraries
import pandas as pd
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import squareform
import seaborn as sns
import numpy as np
import networkx as nx

# grumpsObj object builder
class grumpsObj(object):
    """
    This object is designed to assist and speed up the construction of 
    species level population structures using mash distances as an input.
    ANI values can be used as well if the ANI is converted to a decimal 
    difference value {i.e. (100 - ANI)/100 }
    """

    def __init__(self, mashFile):
        # set fp within the object and try to read it.
        # If wrong filepath, error will be raised
        self.mashFile = mashFile
        try:
            self.distMat = pd.read_csv(self.mashFile, index_col = 0)
        except FileNotFoundError as e:
            print("The name file or folder is incorrect.\
                  An error has occurred.")
            raise FileNotFoundError("The file name or filepath is incorrect. \
Please double check the filepath or file name.") from e
            
        # store empty versions of final data in object at object creation    
        self.outlierDict = dict()
        self.outliercountDF = pd.DataFrame()
        self.cleanGCA = []
        self.mode = 'regular'
        self.cutOff = 0.05
        self.clusterMethod = 'ward'
        self.makeHeatmap = 'yes'
        self.settingString = ''
        self.figFormat = 'png'
        self.targetFilePath = ''
        self.targetList = ''
        self.targetCols = ''
        self.refIndex = []
        self.untrimmedGraph = ''
        self.trimmedGraph = ''
        self.subGraphs = ''
        self.removeFilePath = ''
        self.removeList = ''
        self.removedGCA = []
        self.initialGCA = list(self.distMat.index)
        self.sigma = 'yes'

### functions shared by regular and strict modes
    def outlierFiller(self, clusterCutoff):
        outlierSize = round(len(self.distMat) * .05) + 1
        aboveCutoff = clusterCutoff * 1.02
        outlierSim = clusterCutoff/10
        outlierList = [aboveCutoff]*len(self.distMat)
        outlierDict = dict()
        loopList = [outlierSim] * outlierSize
        for val in range(0,outlierSize):
            self.distMat['outlier_' + str(val)] = outlierList
        for val in range(0,outlierSize):
            subloopList = loopList[:]
            subloopList[val] = 0
            outlierDict['outlier_' + str(val)] = pd.Series((outlierList + subloopList), index = self.distMat.columns)
        outlierDF = pd.DataFrame(outlierDict).T
        self.distMat = pd.concat([self.distMat,outlierDF])

    def outlierCountBuilder(self, clusterCutoff):
        funcDict = dict()
        for col in self.distMat.columns:
            loopSeries = self.distMat[col]
            loopSeries = loopSeries[loopSeries <= clusterCutoff]
            funcDict[col] = loopSeries.index.value_counts()
        funcDF = pd.DataFrame(funcDict)
        funcDF.replace(to_replace = 1, value = 0, inplace = True)
        funcDF.fillna(value = 1, inplace = True)
        statDict = dict()
        for col in funcDF:
            funcSeries = funcDF[col]
            statDict[col] = funcSeries.value_counts()
        self.outliercountDF = pd.DataFrame(statDict)
        self.outliercountDF = self.outliercountDF.T

    def sizeChecker(self, Aclusts):
        if 2 not in Aclusts:
            print('WARNING: Your dataset failed to partition using k-means \
clustering. Most likely this was caused by the dataset \
being too small. You should rerun GRUMPS with the mode set \
to small [grumps -m small ...]')
            return False
        if 2 in Aclusts:
            return True

    def outlierKmeans(self, clusterMethod):
        Z = linkage(self.outliercountDF,  clusterMethod)
        clusts = fcluster(Z, 2, criterion = 'maxclust')
        sizecheck = self.sizeChecker(clusts)
        if sizecheck == True:
            clust1List = list(self.outliercountDF[clusts == 1].index)
            clust2List = list(self.outliercountDF[clusts == 2].index)
            if any('outlier_' in s for s in clust1List):
                return clust2List
            elif any('outlier_' in s for s in clust2List):
                return clust1List
        if sizecheck == False:
            clust1List = [x for x in list(self.outliercountDF[clusts == 1].index) if 'outlier_' not in x]
            return clust1List

### functions shared by regular, strict, target, remover, sigma, and small modes
    def finalDF(self, ):
        self.removedGCA = list(set(self.distMat.index) - set(self.cleanGCA))
        self.distMat.drop(columns = self.removedGCA, index = self.removedGCA, inplace=True)
        self.removedGCA = list(set(self.initialGCA) - set(self.distMat.index))
        
    def cleanDFOutput(self, ):
        try:
            outfp = self.mashFile.split('.csv')[0] + '_cleaned_' + self.settingString + '_distmat.csv'
        except:
            outfp = self.mashFile + '_cleaned_' + self.settingString + '_distmat.csv'
        self.distMat.to_csv(outfp)

    def removedGCAOutput(self, ):
        try:
            outfp = self.mashFile.split('.csv')[0] + '_cleaned_' + self.settingString + '_removed_genomes'
        except:
            outfp = self.mashFile + '_cleaned_' + self.settingString + '_removed_genomes'
        with open(outfp, 'w') as outfile:
            outfile.writelines('\n'.join(self.removedGCA))

    def heatmapMaker(self, clusterMethod):
        try:
            outfp = self.mashFile.split('.csv')[0] + '_cleaned_' + self.settingString + '_heatmap'
        except:
            outfp = self.mashFile + '_cleaned_' + self.settingString + '_heatmap'
        condensedDF = squareform(self.distMat)
        Z = linkage(condensedDF, clusterMethod)
        sns_plot = sns.clustermap(self.distMat, row_linkage = Z, col_linkage = Z, cmap = "BrBG_r",yticklabels=False,xticklabels=False)

        if self.figFormat == 'png':
            sns_plot.savefig(outfp +'.png', dpi = 600, format = 'png')
        if self.figFormat == 'svg':
            sns_plot.savefig(outfp +'.svg', dpi = 600, format = 'svg')
        if self.figFormat == 'pdf':
            sns_plot.savefig(outfp +'.pdf', dpi = 600, format = 'pdf')

### functions for strict mode
    def meanCleaner(self, ):
        statDict = dict()
        self.removedGCA = list(set(self.distMat.index) - set(self.cleanGCA))
        self.distMat.drop(index = self.removedGCA, columns = self.removedGCA, inplace=True)
        for col in self.distMat:
            statDict[col] = np.mean(self.distMat[col])
        cutOff = pd.Series(statDict).mean() + (pd.Series(statDict).std()*3)
        cleanList = list(pd.Series(statDict)[pd.Series(statDict)<=cutOff].index)
        return cleanList
    
### functions for summary mode
    def statBuilder(self,):
        perList = [.3, 1.0, 2.5, 5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0, 60.0, 65.0, 70.0, 75.0, 80.0, 85.0, 90.0, 90.5, 91.0, 91.5, 92.0, 92.5, 93.0, 93.5, 94.0, 94.5, 95.0, 95.5, 96.0, 96.5, 97.0, 97.5, 98.0, 98.5, 99.0, 99.5, 99.6, 99.7, 99.8, 99.9, 99.95, 99.96, 99.97, 99.98, 99.99, 99.995]
        dfStat = pd.concat([pd.concat({'mean':np.mean(self.distMat),'std':np.std(self.distMat),'min':np.min(self.distMat),'max':np.max(self.distMat)}, axis = 1),pd.DataFrame(np.percentile(self.distMat,perList, axis=0), columns = self.distMat.index, index = [str(x)+'%' for x in perList]).T],axis=1)
        meanStat = dfStat['mean'].describe(percentiles = [.003,.1,.25,.5,.75,.9,.997])
        print('The means of your data are described below:')
        print(meanStat)
        specificStat = pd.Series(np.concatenate((np.array([np.shape(self.distMat)[0],np.mean(self.distMat.values),np.std(self.distMat.values)]),np.percentile(self.distMat.values,[.3,10,25,50,75,90,99.7]),np.max(self.distMat.values)), axis = None),index = ['count', 'mean', 'std',' 0.3%', '10%', '25%', '50%', '75%', '90%', '99.7%', 'max'])
        try:
            outfp = self.mashFile.split('.csv')[0] + '_genome_summary_table.csv'
        except:
            outfp = self.mashFile + '_genome_summary_table.csv'
        try:
            outfp2 = self.mashFile.split('.csv')[0] + '_mean_summary_table.csv'
        except:
            outfp2 = self.mashFile + '_mean_summary_table.csv'
        try:
            outfp3 = self.mashFile.split('.csv')[0] + '_overall_summary_table.csv'
        except :
            outfp3 = self.mashFile + '_overall_summary_table.csv'
        dfStat.to_csv(outfp)
        meanStat.to_csv(outfp2, header = False)
        specificStat.to_csv(outfp3, header = False)

    def statSummary(self, ):
        histUnstack =  self.distMat.unstack()
        ax = histUnstack.hist(bins = 1000)
        fig = ax.get_figure()
        try:
            outfp = self.mashFile.split('.csv')[0] + '_summary_histogram'
        except:
            outfp = self.mashFile + '_summary_histogram'
        if self.figFormat == 'png':
            fig.savefig(outfp +'.png', dpi = 600, format = 'png')
        if self.figFormat == 'svg':
            fig.savefig(outfp +'.svg', dpi = 600, format = 'svg')
        if self.figFormat == 'pdf':
            fig.savefig(outfp +'.pdf', dpi = 600, format = 'pdf')

    def distroCheck(self,):
        unstack = self.distMat.unstack()
        distMean = np.mean(self.distMat.values)
        if distMean > 0.05:
            print('\nThe mean of your data is above the species boundary of 0.05. \nYour dataset may contain more than one species. \nPlease run GRUMPS in clique mode before proceeding. \nIf you have already run GRUMPS in clique mode with a cutoff of 0.05, try rerunning GRUMPS in clique mode with a lower cutoff.')
        if self.cutOff != 0.05:
            binList = [0,self.cutOff,1]
        else:
            binList = [0,0.05,1]
        normalCheck = pd.cut(unstack, bins=binList).value_counts(sort=False)/len(unstack)
        normalEval = normalCheck[0] >= .997
        if normalEval == False:
            print('\nLess than 99.7% of your data is contained between 0 and {cutoff}.\n'.format(cutoff=self.cutOff))
        if normalEval == True:
            print('\n99.7% or more of your data is contained between 0 and {cutoff}.\n'.format(cutoff=self.cutOff))

### functions for target mode
    def targetCleaner(self, genomeTargets):
        targetList = []
        for target in genomeTargets:
            for col in self.initialGCA:
                if target in col:
                    targetList.append(col)
        try:
            checkSet = self.distMat[targetList]
            filteredSet = checkSet[checkSet <= self.cutOff]
            filteredSet = filteredSet.dropna()
            returnList = list(filteredSet.index)
            if len(returnList) == 0:
                print('Please check that your targets are correct. There is no \
union between the given targets.')
                return False
            self.removedGCA = list(set(self.initialGCA) - set(returnList))
            self.distMat.drop(columns = self.removedGCA, index = self.removedGCA, inplace=True)
#            self.distMat = self.distMat[returnList]
#            self.distMat = self.distMat.T
#            self.distMat = self.distMat[returnList]
            return True
        except KeyError as e:
            raise KeyError('Please check that your target identifiers are correct and in your dataset.') from e

### functions for clique mode
    def graphBuilder(self, ):
        unstack = self.distMat.unstack()
        unstackIndex = list(unstack.index)
        unstackIndex = [tuple(sorted(i)) for i in unstackIndex]
        unstackIndex = list(set(unstackIndex))
        unstack = unstack[unstack.index.isin(unstackIndex)]
        unstack = unstack[unstack < self.cutOff]
        self.untrimmedGraph = nx.Graph()
        self.untrimmedGraph.add_nodes_from([x[0] for x in list(unstack.index)])
        self.untrimmedGraph.add_edges_from(list(unstack.index))
    
    def graphDivider(self, ):
        i=1
        self.unconnected = []
        funcDict = dict()
        for x in (self.untrimmedGraph.subgraph(c) for c in nx.connected_components(self.untrimmedGraph)):
            if len(list(x.nodes)) > 1:
                funcDict['clique_' + str(i)] = list(x.nodes)
                i+=1
            if len(list(x.nodes)) < 2:
                self.unconnected.extend(list(x.nodes))
        return funcDict
    
    def cliqueWriter(self, ):
        stringy = self.mode + '_' + str(self.cutOff)
        for key in self.graphDict.keys():
            try:
                outfp = self.mashFile.split('.csv')[0] + '_' + key + '_' + stringy + '_distmat.csv'
            except:
                outfp = self.mashFile + '_' + key + '_' + stringy + '_distmat.csv'
            
            loopDF = self.distMat[self.graphDict[key]]
            loopDF = loopDF.T
            loopDF = loopDF[self.graphDict[key]]
            loopDF.to_csv(outfp)
        try:
            outfp = self.mashFile.split('.csv')[0] + '_unconnected_' + stringy + '.txt'
        except:
            outfp = self.mashFile + '_unconnected_' + stringy + '.txt'        
        with open(outfp, 'w') as outfile:
            outfile.write('\n'.join(self.unconnected))
            
### functions for small mode
    def smallModeCleaner(self, ):
        statDict = dict()
        for col in self.distMat:
            loop = self.distMat[col][[x for x in self.distMat.index if col not in x]]
            statDict[col] = loop.describe()
        dfStat = pd.DataFrame(statDict)
        dfStat = dfStat.T
        dfStat = dfStat[dfStat['mean'] <= self.cutOff]
        cleanList = list(dfStat.index)
        return cleanList

### function for sigma mode
    def sigmaModeCleaner(self, ):
        leftDict = dict()
        rightDict = dict()
        for col in self.distMat:
            loopSeries = np.percentile(self.distMat[col], q=[.3,99.7])
            leftDict[col] = loopSeries[0]
            rightDict[col] = loopSeries[1]
        leftStat = pd.Series(leftDict)
        rightStat = pd.Series(rightDict)
        leftCutoff = leftStat.mean() + (3 * leftStat.std())
        rightCutoff = rightStat.mean() + (3 * rightStat.std())
        leftStat = leftStat[leftStat <= leftCutoff]
        rightStat = rightStat[rightStat <= rightCutoff]
        cleanList = list(set(leftStat.index) & set(rightStat.index))
        return cleanList


    
### initialize the parser

# Module test
if __name__ == "__main__":
    import argparse
    usage = """Genomic distance based Rapid Uncovering of Microbial Population\
               Structures. %(prog)s reads a normalized distance matrix  and returns a \
               filtered result.   It can be run in 'summary', 'regular', \
               'strict', 'sigma', 'target', 'clique', and 'small' modes. \
               For more information please see the white \
               paper: doi:1-.--.----"""

    descript = """%(prog)s is designed to assist and speed up the construction \
               of species level population structures using Mash distances as \
               an input. ANI values can be used as well if the ANI values are \
               converted to a decimal difference value {i.e. (100 - ANIvalue)\
               /100}. Additional helper scripts are provided if you do not \
               have a correctly formated distance matrix to input."""
                              
               
               
    parser = argparse.ArgumentParser(description=usage, epilog = descript)
    parser.add_argument("-v", "--version", action="version", version="%(prog)s\
                        v{} ({}) By: {}\
                        ".format(__version__, __date__, __author__))    
            
    parser.add_argument("filepath", metavar="filepath",
                        help="The filepath to a mash distance matrix \
                        with genome ID (any unique string can be used as \
                        a genome ID) as both column and index. \
                        ", type=str)
    parser.add_argument("-m", "--mode", dest="mode", metavar = "MODE",
                        help="Specify the mode GRUMPS runs in. \
                        Available modes are: 'summary', 'regular', 'strict', \
                        'sigma', 'clique', 'target', 'remover', and 'small'. \
                        Please refer to the white paper or GitHub for more \
                        information concerning the usage for each mode.\
                        [default: 'regular']", choices=['summary', 'regular', 
                        'strict','sigma', 'clique', 'target', 
                        'remover','small'] ,\
                        default='regular',type=str)
    parser.add_argument("-c", "--cutoff", dest="cutoff", metavar = 'CUTOFF',
                        help="The maximun distance threshold to \
                        which species membership will be determined. \
                        [default: 0.05]", default = 0.05, type=float)
    parser.add_argument("-s", "--sigma", dest="sigma", metavar = 'SIGMA',
                        help="Perform sigma cleaning step after 'regular' \
                        or 'strict' cleaning modes. [default: yes]\
                        ", choices = ['yes', 'no'], default = 'yes', type=str)
    parser.add_argument("-p","--heatmap", dest="heatMap", metavar = 'HEATMAP',
                        help = "If heatmap\
                        should be made at the end of program. Valid only for \
                        'regular', 'strict', 'sigma', 'target', \
                        'remover', and 'small' modes. [default: 'yes']\
                        ", choices = ['yes', 'no'], default = 'yes', 
                        type = str)
    parser.add_argument("-o", "--clustermethod", dest = "clustermethod",
                        metavar = 'CLUSTERMETHOD',
                        help = "The type of method to use in \
                        scipy.cluster.hierarchy.linkage(). Options \
                        include: 'single', 'complete', 'average', 'weighted'\
                        , 'centroid', 'median', or 'ward'.\
                        [default: 'ward']", default = 'ward', \
                        choices = ['single', 'complete', 'average', 
                        'weighted''centroid', 'median','ward'], type=str)
    parser.add_argument("-f", "--figformat", dest="figformat", 
                        metavar = 'FIGFORMAT',
                        help="The format of any images generated by the \
                        script. Options are: 'png', 'svg', and 'pdf'. \
                        Note: 'svg' \
                        and 'pdf' modes are not recommended for heatmaps made \
                        with 'regular' or 'strict' modes. For publication \
                        quality heatmaps use the R script. [default: 'png']\
                        ", choices = ['png', 'svg', 'pdf'], 
                        default = 'png', type=str)
    parser.add_argument("-t", "--target", dest="targetFP",
                        help="If one or more genomes is required to be in the \
                         final dataset, you can specify the genome ID. This is \
                         a useful option where a species has significant \
                         contamination but a genome \
                         should be included in the cleaned species. The genome\
                          ID must be identical to the genome ID in the \
                          distance matrix.", type=str)
    parser.add_argument('-r', '--remove', dest='removeFP',
                        help="If one or more genomes to be removed from the \
                         final dataset, you can specify the genome ID(s). This \
                         is a useful option where a species has genomes \
                         that should not \
                         be included in the cleaned species. The genome\
                         ID(s) must be identical to the genome ID in the \
                         distance matrix.", type=str)
    
# store the parser arguments
    args = parser.parse_args()
    filepath = args.filepath
    cutoff = args.cutoff
    heatmap = args.heatMap
    mode = args.mode
    clustermethod = args.clustermethod
    figFormat = args.figformat
    targetFilePath = args.targetFP
    removeFilePath = args.removeFP

### initialize the mash object with defaults before setting arg vars
    grumps = grumpsObj(filepath)

### check for arg vars and set them within the mash object
    if args.mode:
        grumps.mode = args.mode

    if args.cutoff:
        grumps.cutOff = args.cutoff

    if args.clustermethod:
        grumps.clusterMethod = args.clustermethod
        
    if args.heatMap:
        grumps.makeHeatmap = args.heatMap
    
    if args.figformat:
        grumps.figFormat = args.figformat
    
    if args.targetFP:
        grumps.targetFilePath = args.targetFP
    
    if args.removeFP:
        grumps.removeFilePath = args.removeFP
    
    if args.sigma:
        grumps.sigma = args.sigma
    
    grumps.settingString = grumps.mode + '_' + \
    str(grumps.cutOff) + '_' + grumps.clusterMethod
                   
### mode  == 'regular'
    if args.mode == 'regular':
        # if cutoff is set by user run that value is used otherwise 0.05
        grumps.outlierFiller(grumps.cutOff)
        grumps.outlierCountBuilder(grumps.cutOff)
        grumps.cleanGCA = grumps.outlierKmeans(grumps.clusterMethod)

        # make clean dataframe for outputting
        grumps.finalDF()

        if grumps.sigma == 'yes':
        # now run sigma cleaner
            grumps.cleanGCA = grumps.sigmaModeCleaner()
            grumps.settingString = grumps.mode + '_' + 'sigma_'+ str(grumps.cutOff) + '_' + grumps.clusterMethod
        # make clean dataframe for outputting
            grumps.finalDF()

        # if user doesn't disable heatmap this will trigger and make the heatmap    
        if grumps.makeHeatmap == 'yes':
            grumps.heatmapMaker(grumps.clusterMethod)
        # outputs the final clean dataframe        
        grumps.cleanDFOutput()
        # write out the removed genome list 
        grumps.removedGCAOutput()

### mode == 'strict'    
    if args.mode == 'strict':
        # if cutoff is set by user run that value is used otherwise 0.05
        grumps.outlierFiller(grumps.cutOff)
        grumps.outlierCountBuilder(grumps.cutOff)
        grumps.cleanGCA = grumps.outlierKmeans(grumps.clusterMethod)
        grumps.cleanGCA = grumps.meanCleaner()

    # make clean dataframe for outputting
        grumps.finalDF()

        if grumps.sigma == 'yes':
        # now run sigma cleaner
            grumps.cleanGCA = grumps.sigmaModeCleaner()
            grumps.settingString = grumps.mode + '_' + 'sigma_'+ str(grumps.cutOff) + '_' + grumps.clusterMethod
        # make clean dataframe for outputting
            grumps.finalDF()
    
    # if user doesn't disable heatmap this will trigger and make the heatmap    
        if grumps.makeHeatmap == 'yes':
            grumps.heatmapMaker(grumps.clusterMethod)
    # outputs the final clean dataframe        
        grumps.cleanDFOutput()
    # write out the removed genome list 
        grumps.removedGCAOutput()
    
### mode == 'summary'    
    if args.mode == 'summary':
        grumps.distroCheck()
        grumps.statBuilder()
        grumps.statSummary()

### mode == 'target'
    if args.mode == 'target':
    # attempt to open file with target ID list 
        try:
            with open(grumps.targetFilePath, 'r') as infile:
                grumps.targetList = infile.readlines()
            # save the list in the object
            grumps.targetList = [x.split('\n')[0] for x in grumps.targetList]
            grumps.targetSuccess = grumps.targetCleaner(grumps.targetList)
            if grumps.targetSuccess == True:
                if len(grumps.distMat) < len(grumps.initialGCA):
        # if user doesn't disable heatmap this will trigger and make the heatmap    
                    if grumps.makeHeatmap == 'yes':
                        grumps.heatmapMaker(grumps.clusterMethod)
            # outputs the final clean dataframe
                    grumps.cleanDFOutput()
                    # write out the removed genome list 
                    grumps.removedGCAOutput()
                if len(grumps.distMat) == len(grumps.initialGCA):
                    print('The provided targets did not filter any genomes.')
                    print('If this is unexpected, please double check the provided targets.')
        except FileNotFoundError as e:
            raise FileNotFoundError("The file: \"" + grumps.targetFilePath + '\" \
cannot be found. Please double check the file name and provide the complete \
filepath to \"-t\" when running in target mode.') from e
        
### mode == 'clique'
    if args.mode == 'clique':
        grumps.graphBuilder()
        grumps.graphDict = grumps.graphDivider()
        grumps.cliqueWriter()
        
### mode == 'small'
    if args.mode == 'small':
    # identify genomes where average (ignoring self-self) is > than cutoff
        grumps.cleanGCA = grumps.smallModeCleaner()
        # make clean dataframe for outputting
        grumps.finalDF()
    # if user doesn't disable heatmap this will trigger and make the heatmap    
        if grumps.makeHeatmap == 'yes':
            grumps.heatmapMaker(grumps.clusterMethod)
        # outputs the final clean dataframe
        grumps.cleanDFOutput()
    # write out the removed genome list 
        grumps.removedGCAOutput()

### mode == 'remover'
    if args.mode == 'remover':
    # attempt to open file with list of IDs to remove
        try:
            with open(grumps.removeFilePath, 'r') as infile:
                grumps.removeList = infile.readlines()
            grumps.removeList = [x.split('\n')[0] for x in grumps.removeList]
            # identify genomes to retain
            grumps.cleanGCA = list(set(list(grumps.distMat.index)) - set(grumps.removeList))
            # create the clean dataframe for the target genomes
            grumps.finalDF()
            # if user doesn't disable heatmap this will trigger and make the heatmap    
            if grumps.makeHeatmap == 'yes':
                grumps.heatmapMaker(grumps.clusterMethod)
            # output the final clean dataframe
            grumps.cleanDFOutput()
        # write out the removed genome list 
            grumps.removedGCAOutput()
        except FileNotFoundError as e:
            raise FileNotFoundError("The file: \"" + grumps.targetFilePath + '\" \
cannot be found. Please double check the file name and provide the complete \
filepath to \"-r\" when running in remover mode.') from e

### mode == 'sigma'
    if args.mode == 'sigma':
    # if cutoff is set by user run that value is used otherwise 0.05

        # now run sigma cleaner
        grumps.cleanGCA = grumps.sigmaModeCleaner()
        # make clean dataframe for outputting
        grumps.finalDF()

        # if user doesn't disable heatmap this will trigger and make the heatmap    
        if grumps.makeHeatmap == 'yes':
            grumps.heatmapMaker(grumps.clusterMethod)
        # outputs the final clean dataframe        
        grumps.cleanDFOutput()
        # write out the removed genome list 
        grumps.removedGCAOutput()
